\chapter{Related Work}\label{chapter:related}

\toolname combines ideas from four main lines of research areas. 
%
It is a 
refinement type checker (\S~\ref{related:refinementtypes})
that enjoys SMT-based (\S~\ref{related:smtbased}) automated type checking. 
Via Refinement Reflection we touch the expressiveness 
of fully dependently typed systems (\S~\ref{related:dependenttypes}), 
getting an automated and expressive verifier for Haskell programs (\S~\ref{related:haskell}).  
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Classic refinement types %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Refinement Types}\label{related:refinementtypes}


\mypara{Standard Refinement Types}
Refinement Types were introduced by Freeman and
Pfenning~\cite{FreemanPfenning91}, with refinements limited to
restrictions on the structure of algebraic datatypes. 
%
Freeman and Pfenning carefully designed the refinement logic 
to ensure \textit{decidable type inference}
via the notion of predicate subtyping (PVS~\cite{Rushby98}).
% 
The goal of refinement types is 
to refine the type system of an existing, general purpose,  
target language so that it
\textit{rejects more programs} as ill typed, 
unlike dependent type systems, 
that aim to increase the expressiveness 
and alter the semantics of the language.

\mypara{Applications of Refinement Types}
Xi and Pfenning implemented DML~\cite{pfenningxi98}
a refinement type checker for ML 
where arrays are indexed by terms 
from Presburger arithmetic to statically eliminate array bound checking. 
%
Since then, refinement types have been implemented for various general purpose languages, 
including 
ML~\cite{GordonTOPLAS2011,LiquidPLDI08},
C~\cite{deputy,LiquidPOPL10},
Racket~\cite{RefinedRacket}
and Scala~\cite{refinedscala}
to prove various correctness properties ranging from safe memory accessing 
to correctness of security protocols.
%
All the above systems operate under CBV semantics 
that implicitly assume that all free variables are bound to values. 
%
This assumption, that breaks under Haskell's lazy semantics,
turned out to be crucial for the soundness 
of refinement type checking.
To restore soundness in \toolname we 
use a refinement type based termination checker 
to distinguish between provably terminating and potential diverging free variables. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Extensions of refinement types %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mypara{Reconciliation between Expressiveness and Decidability}
Reluctant to give up decidable type checking, 
many systems have pushed the expressiveness of refinement types
within decidable logics. 
%
Kawaguchi \etal~\cite{LiquidPLDI09} 
introduce \emph{recursive} and \emph{polymorphic} refinements for data
structure properties increasing the expressiveness but also the complexity 
of the underlying refinement system. 
%
\catalyst~\citep{catalyst} permits a form of
higher order specifications where refinements
are relations which may themselves be parameterized
by other relations.
%
However, to ensure decidable checking, \catalyst
is limited to relations that can be specified as
catamorphisms over inductive types, precluding
for example, theories like arithmetic.
%
In the same direction, Abstract and Bounded refinement types 
encode modular, higher order specifications 
using the decidable theory of uninterpreted functions. 
% 
All the above systems
only allow for ``shallow'' specifications, 
where the underlying solver can only reason about 
(decidable) abstractions of user defined functions 
and not the exact description of the function  implementations of the functions. 
%
Refinement Reflection, on the other hand, 
reflects user defined function definitions 
into the logic, allowing for ``deep'' program specifications
but requiring the user to manually provide cumbersome proof terms. 



\section{SMT-Based Verification}\label{related:smtbased}

Even though refinement type systems use SMT solvers to 
achieve decidable program verification by highly constraining the 
expressiveness of specifications,
%
SMT-based verification has been extensively used for program verification 
without the decidability constraint. 
%
In such verifiers the SMT solvers are used to decide validity of 
arbitrary (\ie non strictly decidable) logics leading to expressive specifications
but undecidable and unpredictable verification. 
Unpredictable verification, as described in~\cite{Leino16}, suffers from  
\textit{the butterfly effect} as ``a minor modification in one
part of the program source causes changes in the outcome of the verification in other,
unchanged and unrelated parts of the program''.
%
Here we present three SMT-based verifiers that have highly influenced 
the design decisions in \toolname 
and discuss the ways each one of them uses to control the unpredictability of verification. 



\mypara{Sage}~\cite{Knowles10} is a hybrid type checker. 
The specifications are expressed in the form of refinement types 
that allow predicates to
be arbitrary terms of the language being typechecked. 
It uses the SMT solver Simplify~\cite{simplifyj} to statically discharge 
as many proof obligations as possible and defers the rest to runtime casts. 
%
\toolname is a subset of Sage that provably requires no runtime casts
since predicates are carefully constrained to decidable logics. 
%
We used Knowles and Flanagan's formalism on denotational typing 
and correctness of Sage to formalize soundness and semantics of \toolname.  
 

\mypara{\fstar}~\cite{fstar} is a refinement type checker 
that allows predicates to be arbitrary terms 
and aims to discharge all proof obligations via the SMT solver, 
leading to unpredictable verification. 
%
\fstar allows the user to control the SMT decision procedures 
by exposing to the user SMT tactics that can be used to direct
verification in case of failure. 
% 
Moreover, \fstar allows effectful computations 
(\eg state, exceptions, divergence and IO)
and combines refinement types with a sophisticated effect type system 
to reason about totality of programs. 
%
In (Liquid) Haskell all programs are pure, thus reasoning about effectful
computations has already been taken care of by Haskell's basic (\ie unrefined) 
type system that requires effectful computations to be wrapped inside monads. 
% 
The only effects allowed in Haskell are exceptions and divergence 
that can be optionally tracked by \toolname's totality and termination checker respectively. 


\mypara{Dafny}~\cite{dafny} is a prototype SMT-based verifier 
for imperative programs that allows arbitrarily expressive specifications 
in the form of pre- and post-conditions. 
%
Acknowledging the disadvantages of unpredictable verification, 
Dafny aims to give to the user control over the underlying SMT 
decision procedures 
via sophisticated trigger and fuel techniques. 
%
Dafny
that verifies effectful, imperative code via pre- and post-conditions
is quite different from \toolname
that verifies the pure and functional Haskell via refinement types. 
%
Yet, the work of Leino and the rest of Dafny developers 
has been a great inspiration for existing and future work 
on challenges shared by both verifiers, 
including termination checking, 
coinduction~\cite{LeinoM14}, 
local calculations~\cite{LeinoPolikarpova16}, 
and error reporting~\cite{GouesLM11}. 


\section{Dependent Type Systems}\label{related:dependenttypes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Fully dependent typing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dependent Types Systems like Coq~\cite{coq-book}, 
Agda~\cite{norell07}, Idris~\cite{Brady13} and Isabelle/HOL~\cite{isabelle}
express sophisticated theorems as types since they 
allow arbitrary terms to appear in the types.
%
Constructive proofs of such theorems are just programs
that are either manually written by the users or automatically generated via 
proof tactics and heuristics.
However programs are not just proofs, 
thus, unlike \toolname, these verification oriented, dependent type systems
fail to provide an environment for mainstream code development. 

\mypara{Expressiveness: Deep vs. Shallow Specifications}
Dependently typed languages permit
\textit{deep} specification and verification. 
%
To express and prove theorems, these systems
represent and manipulate the exact
descriptions of user-defined functions. 
%
For example, we can represent
the specification that the list @append@ function is associative and
we can manipulate (unfold) its definition 
to write a small program that by reduction
constructs a proof of the specification.
%
On the other hand, 
standard refinement types, including \toolname without refinement reflection,  
restrict refinements to so-called  \textit{shallow}
specifications that correspond to abstract interpretations of
the behavior of functions within decidable logical domains. 
%
For example, refinements make it easy
to specify that the list returned by the @append@ function has size
equal to the sum of those of its inputs
but in the logic the exact definition of @append@ is not known. 
%
Refinement Reflection reflects user defined functions into the logic
allowing deep specifications. 
Verification still occurs using the abstract interpretations of the functions, 
but with refinement reflection, the abstraction of the function is 
exactly equal to its definition. 

\mypara{Proof Strategy: Type Level Computations vs. Abstract Interpretation}
Dependent type systems use type level computations to construct proofs by evaluation. 
%
On the other hand, in refinement type systems, 
safety proofs rely on validity of subtyping constraints 
that is checked externally by an SMT solver. 
%
That is, the type system is unable to perform any proof by evaluation, 
as the only information it has for each function is the abstraction that is 
described by its type.
%
With refinement reflection, we fake type level computations: 
the Haskell, value level, proof terms provide all the required reduction steps
that are then retrofitted as equality assertions to the SMT solver.


\mypara{Automation: Tactics vs. SMT solvers}
Dependent type checking requires explicit proof terms to be provided by the users. 
%
To help automate proof term generation, both built-in and user-provided
tactics and heuristics are used to attempt to discharge proof obligations; however,
the user is ultimately responsible for manually proving any
obligations which the tactics are unable to discharge.
%
On the other hand, refinement type checking 
does not require explicit proof terms. 
%
Verification proceeds by checking validity of subtyping constraints 
which reduces to implication checking that is in turn
decided using the power of SMT solvers. 
%
Many times the SMT solver fails to prove 
validity of a subtyping constraint because the environment is too weak. 
%
In such cases the user can strengthen the environment by instantiating 
axioms via function calls. 
%
For example, the proof that @() :: {v:() | fib 1 = 1}@ 
is valid under an environment that invokes @fib@ on @1@.
%
That is, to prove deep specifications we fake type level computations
via value level proof terms, but ultimately, 
we check validity using the power of SMTs
which drastically simplifies proofs over key theories
like linear arithmetic and equality.
%
In the future, we plan to investigate how to simplify such proof terms
by adapting the tactics and heuristics of dependently typed systems
into \toolname. 

\mypara{System Features: Theorem Prover vs. Legacy Programming Languages}
Dependent type systems are proof oriented systems, lacking 
features required for a general purpose language, like 
diverging and effectful programs. 
%
Various systems extend theorem provers to support effectful programs, 
for example 
Zombie~\cite{Zombie,Sjoberg2015} and \fstar~\cite{fstar} allow dependent types to
coexist with divergent and effectful programs. 
%
Still, these systems are verification oriented and lack the 
optimized libraries that come from the mainstream developers of 
a general purpose programming language.  
%
On the other hand, \toolname 
retrofits verification in Haskell,
a legacy programming language with 
a long-standing developer community. 
%
With \toolname, 
Haskell programmers can as use their favorite  
language for general purpose programming, 
and also prove specifications without the need to use an external, 
verification specific, theorem prover. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% alternative verification in Haskell %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Haskell Verifiers}\label{related:haskell}

\toolname belongs into the ongoing research of Haskell code verification
that is exploring techniques to verify properties about Haskell programs
that the current type system cannot specify. 
%
There are two main directions in this line of research. 
%
Some groups are building external verifiers that analyze 
well typed Haskell programs, while others are enriching 
the expressiveness of the Haskell's type system. 

\mypara{Domain Specific Haskell Verifiers}
Various external Haskell analyzers have been proposed 
to check correctness properties of Haskell code that 
is not expressible by Haskell's type system. 
%
Catch~\cite{catch} is
a fully automated tool that tracks incomplete patterns,
like our totality analyzer. 
AProVE~\cite{Giesl11} implements a powerful, fully-automatic
termination analysis for Haskell based on term-rewriting,
like our termination analyzer. 
HERMIT~\citep{Farmer15} proves equalities by rewriting
the GHC core language, guided by user specified scripts, 
like our equality reasoning performed via Refinement Reflection.
%
All the above verifiers allow for a domain specific analysis, 
precluding \toolname's generalized functional 
correctness specifications, encoded via refinement typing. 
%

\mypara{Static Contract Checking}
A generalized correctness analysis in Haskell is feasible 
via Haskell's static contract checking~\cite{XuPOPL09} 
that encodes arbitrary contracts in the form of refinement types and
checks them using symbolic execution to unroll procedures
upto some fixed depth.
%
Similarly, Zeno~\cite{ZENO} is an automatic Haskell 
prover that combines unrolling with heuristics for rewriting
and proof-search. 
%
Finally, the Halo~\cite{halo} contract checker encodes 
Haskell programs into first-order logic by directly 
modeling the code's denotational semantics,
again, requiring heuristics for instantiating axioms 
describing functions' behavior.
%
All the above general purpose verifiers 
allow specification of arbitrarily expressive contracts
rendering verification undecidable and thus impractical. 


 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% dependent types in Haskell %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
 
\mypara{Dependent Types in Haskell}
Haskell itself is a dependently-typed language~\cite{Eisenberg16},
as type level computation is allowed via 
Type Families~\cite{McBride02},
Singleton Types\cite{Weirich12}, 
Generalized Algebraic  Datatypes (GADTs)~\cite{JonesVWW06, SchrijversJSV09}, 
type-level functions~\cite{ChakravartyKJ05}, 
and explicit type applications~\cite{EisenbergWA16}. 
%
In this line of work~\citep{EisenbergS14}
Eisenberg \etal aim to allow fully dependent
programming within Haskell, by making
``type-level programming ... at least as
  expressive as term-level programming''.
%
Our approach differs in two significant ways.
%
First, while enriching expressiveness of the types
allows Haskell's type system to accept more programs, 
we aim not to alter semantics of Haskell programs, 
but by refining the checks performed by the type system 
to reject more programs as ill typed. 
%
As a consequence, refinements are completely erased at run-time.
%
As an advantage (resp. disadvantage), refinements
cannot degrade (resp. optimize)
the performance of programs.
%
Second, dependent Haskell follows the classic dependent type 
verification by type level evaluation approach
that turns out to be quite painful~\cite{LindleyM13}.
On the other hand, \toolname 
enjoys SMT-aided verification,
which drastically simplifies proofs over key theories
like linear arithmetic and equality.
%
Despite these differences, these two approaches target 
the same problem of lifting value level terms into Haskell's type system. 
%
In the future, we hope to unify these two techniques and 
allow a uniform interface for lifting values inside the type specifications
to create a dependent Haskell
that enjoys 
both SMT-based automation of verification and  
type driven runtime optimizations. 










\begin{comment}

Much of this simplicity can be recovered in
Haskell using the @singleton@ library~\citep{Weirich12}.
%
Our goal is to show that bounded refinements
are expressive enough to permit the construction
of rich abstractions like a relational algebra
and generic combinators for safe database access
while using SMT solvers to provide decidable
checking and inference. Further, unlike the
HList based approaches, refinements they can
be used to \emph{retroactively} or \emph{gradually}
verify safety; if we erase the types we still
get a valid Haskell program operating over
homogeneous lists.
We do not extende Haskell's expressivity 


\spara{Tracking Divergent Computations}
The notion of type stratification to track potentially 
diverging computations dates to at least~\citep{ConstableS87} 
which uses $\bar{\typ}$ to encode diverging terms, and types 
$\efix{}$ as $(\bar{\typ}\rightarrow\bar{\typ}) \rightarrow \bar{\typ}$).
%
More recently, \cite{Capretta05} tracks diverging 
computations within a \emph{partiality monad}.
%
Unlike the above, we use refinements to 
obtain terminating fixpoints (\etfix{}), which let us prove 
the vast majority (of sub-expressions) in real world libraries 
as non-diverging, avoiding the restructuring that would
be required by the partiality monad.

\spara{Termination Analyses}
Various authors have proposed techniques to verify termination 
of recursive functions, either using the ``size-change principle'' 
\cite{JonesB04,Sereni05}, or by annotating types with size indices 
and verifying that the arguments of recursive calls have smaller 
indices~\cite{HughesParetoSabry96,BartheTermination}.
%
Our use of refinements to encode terminating fixpoints is most 
closely related to~\cite{XiTerminationLICS01}, but this work 
also crucially assumes CBV semantics for soundness.

AProVE~\cite{Giesl11} implements a powerful, fully-automatic
termination analysis for Haskell based on term-rewriting.
%
While we could use an external analysis like AProVE,
we have found that encoding the termination proof via 
refinements provided advantages that are crucial in 
large, real-world code bases. Specifically, refinements
let us
%
(1) prove termination over a subset 
    (not all) of inputs; many functions (\eg @fac@) 
    terminate only on @Nat@ inputs and not all @Int@s,
%
(2) encode pre-conditions, 
    post-conditions, and auxiliary invariants that 
    are essential for proving termination, (\eg @gcd@),
%
(3) easily specify non-standard 
    decreasing metrics and prove termination, (\eg @range@).
%
In each case, the code could be (significantly) 
\emph{rewritten} to be amenable to AProVE but this defeats
the purpose of an automatic checker.
%
Finally, none of the above analyses have been empirically
evaluated on large and complex real-world libraries.


\spara{Static Contract Checkers} 
like ESCJava~\cite{ESCJava} are a classical way of verifying 
correctness through assertions and pre- and post-conditions. 
%
Side-effects like modifications of global variables are a 
well known issue for static checkers for imperative languages;
the standard approach is to use an effect analysis to determine
the ``modifies clause'' \ie the set of globals modified by a procedure.
%
Similarly, one can view our approach as implicitly computing 
the non-termination effects.
%
%
\cite{XuPOPL09} describes a static contract checker for 
Haskell that uses symbolic execution to unroll procedures
upto some fixed depth, yielding weaker ``bounded'' soundness
guarantees.
% 

%
Similarly, Zeno~\cite{ZENO} is an automatic Haskell 
prover that combines unrolling with heuristics for rewriting
and proof-search. 
Based on rewriting, it is sound but 
``Zeno might loop forever'' when faced with 
non-termination.
%
Finally, the Halo~\cite{halo} contract checker encodes 
Haskell programs into first-order logic by directly 
modeling the code's denotational semantics,
again, requiring heuristics for instantiating axioms 
describing functions' behavior. Halo's translation of Haskell
programs directly encodes constructors as uninterpreted functions,
axiomatized to be injective (as the denotational semantics requires).
This heavyweight encoding is more precise than predicate abstraction 
but leads to model-theoretic problems (outlined in the Halo paper) and 
affects the efficiency of the encoding when scaling to larger programs 
(see also \ref{sec:refinedhaskell:conclusion}, paragraph B) in the lack of specialized 
decisions procedures.
%
Unlike any of the above, our type-based approach does 
not rely on heuristics for unrolling recursive procedures, 
or instantiating axioms. 
%
Instead we are based on decidable SMT validity 
checking and abstract interpretation~\cite{LiquidPLDI08} 
which makes the tool predictable and the overall workflow
scale to the verification of large, real-world
code bases.


\paragraph{Parallel Code Verification}
Dependent type theorem provers have been used before to
verify parallel code.
%
BSP-Why~\cite{bspwhy} is an extension to Why2 that is using both Coq and SMTs
to discharge user specified verification conditions.
%
Daum~\cite{daum07} used Isabelle to formalize the semantics
of a type-safe subset of C, 
by extending Schirmer's~\cite{schirmer06}
formalization of sequential imperative languages.
%
Finally, Swierstra~\cite{wouter10} formalized mutable arrays in Agda
and used them to reason about distributed maps and sums.

\mypara{Deterministic Parallelism}
%
Deterministic parallelism has plenty of theory but relatively few practical
implementations.  Early discoveries were based on limited producer-consumer
communication, such as single-assignment variables \cite{Tesler-1968,IStructures}, Kahn
process networks~\cite{kahn-1974}, and synchronous dataflow~\cite{lee-sdf}.
Other models use synchronous updates to shared state, as in
Esterel~\cite{synchronous-overview} or PRAM.  Finally, work on type systems for
permissions management \cite{permission-types,habanero-java-permissions},
supports the development of {\em non-interfering} parallel programs that access
disjoint subsets of the heap in parallel.  Parallel functional programming is
also non-interfering~\cite{manticore,multicore-ghc}.
%
Irrespective of which theory is used to support deterministic parallel
programming, practical implementations such as Cilk~\cite{cilk} or Intel
CnC~\cite{cnc} are limited by host languages with type systems insufficient to
limit side effects, much less prove associativity.  Conversely, dependently
typed languages like Agda and Idris do not have parallel programming APIs and
runtime systems.

% synchronous languages such as Esterel
\mypara{Our Approach for Verifying Stateful Computations} using monads
indexed by pre- and post-conditions is inspired by the method of
Filli\^atre~\citep{Filliatre98}, which was later enriched with
separation logic in Ynot~\citep{ynot}. In future work it would
be interesting to use separation logic based refinements to specify
and verify the complex sharing and aliasing patterns allowed by Ynot.
%
\fstar encodes stateful computations in a special Dijkstra
Monad~\citep{dijkstramonad} that replaces the two assertions with
a single (weakest-precondition) predicate transformer which
can be composed across sub-computations to yield a transformer
for the entire computation.
%
Our \RIO approach uses the idea of indexed monads but
has two concrete advantages.
%
First, we show how bounded refinements alone suffice to
let us fashion the \RIO abstraction from scratch.
%
Consequently, second, we automate inference of pre- and
post-conditions and loop invariants as refinement instantiation
via Liquid Typing~\citep{LiquidPLDI08}.


Systems~\citep{sousa16} and \citep{KobayashiRelational15}
extend classical safety verification algorithms,
respectively based on Floyd-Hoare logic and Refinement Types,
to the setting of relational or $k$-safety properties
that are assertions over $k$-traces of a program.
%
Thus, these methods can automatically prove that
certain functions are associative, commutative \etc.
but are restricted to first-order properties and
are not programmer-extensible.
%
Zeno~\citep{ZENO} generates proofs by term
rewriting and Halo~\citep{halo} uses an axiomatic
encoding to verify contracts.
%
Both the above are automatic, but unpredictable and not
programmer-extensible, hence, have been limited to
far simpler properties than the ones checked here.




\paragraph{Parallel Code Verification}

One work  closely related to ours is
SyDPaCC~\cite{SyDPaCC}, a Coq library that
automatically parallelizes list homomorphisms
by extracting parallel Ocaml versions of user provided Coq functions.
%
Unlike SyDPaCC, we are not automatically generating the parallel
function version, because of engineering limitations
(\S~\ref{sec:evaluation}).  Once these are addressed, code extraction
can be naturally implemented by turning
Theorem~\ref{theorem:two-level} into a Haskell type class with a
default parallelization method.
%
SyDPaCC used maximum prefix sum as a case study,
whose morphism verification is
much simpler than our string matching case study.
%
Finally, our implementation consists of
2K lines of Liquid Haskell, which we consider verbose and aim to
use tactics to simplify.
On the contrary, the SyDPaCC implementation
requires three different languages:
2K lines of Coq with tactics, 600 lines of Ocaml and 120 lines of C,
and is considered ``very concise''.

\mypara{Dependent Types for Non-Terminating Programs}
%
Zombie~\citep{Zombie, Sjoberg2015} integrates
dependent types in non terminating programs
and supports automatic reasoning for equality.
%
Vazou \etal have previously~\citep{Vazou14} shown
how Liquid Types can be used to check
non-terminating programs.
%
Reflection makes \toolname at least as
expressive as Zombie, \emph{without}
having to axiomatize the theory of
equality within the type system.
%
Consequently, in contrast to Zombie,
SMT based reflection lets \toolname
verify higher-order specifications
like @foldr_fusion@.

\end{comment}