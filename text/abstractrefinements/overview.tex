\section{Overview}\label{sec:abstractrefinements:overview}

We start with a high level overview of abstract refinements, 
by illustrating how they can be used to uniformly specify and 
automatically verify various kinds of invariants.

\subsection{Parametric Invariants}\label{sec:overview:parametric}

\mypara{Parametric Invariants via Type Polymorphism}
Suppose we had a generic comparison @(<=) :: a -> a -> Bool@ as in
\ocaml.
We could use it to write: 
\begin{code}
  max     :: a -> a -> a
  max x y = if x <= y then y else x 

  maximum :: [a] -> a
  maximum (x:xs) = foldr max x xs
\end{code}
In essence, the type given for @maximum@ states that
\emph{for any} @a@, if a list of @a@ values is passed
into @maximum@, then the returned result is also an @a@
value.
%
Hence, for example, if a list of \emph{prime} numbers 
is passed in, the result is prime, and if a list of 
\emph{even} numbers is passed in, the result is even. 
Thus, we can use refinement types \cite{LiquidPLDI08} 
to verify
%
\begin{code}
  type Even = {v:Int | v % 2 = 0 }

  maxEvens :: [Int] -> Even
  maxEvens xs = maximum (0 : xs') 
    where xs' = [ x | x <- xs, x `mod` 2 == 0]
\end{code}
%
Here the @%@ represents the modulus operator in the refinement logic
\cite{z3} and we type the primitive {@mod :: x:Int -> y:Int -> {v: Int | v = x % y}@}.
Verification proceeds as follows.
Given that {@xs :: [Int]@}, the system has to verify that
{@maximum (0 : xs') :: Even@}.
%
To this end, the type parameter of @maximum@ is instantiated with the 
\emph{refined} type @Even@, yielding the instance:
%
\begin{code}
  maximum :: [Even] -> Even
\end{code}
%
Then, @maximum@'s argument should be proved to have type
{@[Even]@}.
So, the type parameter of @(:)@ 
is instantiated with {@Even@}, yielding the instance: 
%
\begin{code}
  (:) :: Even -> [Even] -> [Even]
\end{code}
%
Finally, the system infers that {@0 :: Even@} and {@xs' :: [Even]@}, 
\ie the arguments of {@(:)@} have the expected types, thereby verifying
the program.
%
The refinement type instantiations can be inferred,
from an appropriate set of logical qualifiers, 
using the abstract interpretation framework of Liquid
Types~\cite{LiquidPLDI08}.
Here, once 
@ v%2 = 0 @ 
is added to the set of qualifiers, either manually or (as done by 
our implementation) by automatically scraping predicates from 
refinements appearing in specification signatures, the 
refinement type instantiations and hence verification, proceed 
automatically.
%
Thus, parametric polymorphism offers an easy means of encoding 
second-order invariants, \ie of quantifying over or parametrizing 
the invariants of inputs and outputs of functions. 

\mypara{Parametric Invariants via Abstract Refinements}
Instead, suppose that the comparison operator was monomorphic and only
worked for @Int@ values. The resulting (monomorphic) signatures
\begin{code}
  max     :: Int -> Int -> Int
  maximum :: [Int] -> Int
\end{code}
preclude the verification of @maxEvens@ (\ie typechecking against the 
signature shown earlier). This is because the new type of @maximum@ 
merely states that \emph{some} @Int@  is returned as output and not 
necessarily one that enjoys the properties of the values in the input
list. This is a shame, since the property clearly still holds.
We could type
%@max :: forall t <: Int. t -> t -> t@
\begin{code}
  max :: forall t <: Int. t -> t -> t
\end{code}
but this route would introduce the complications
that surround bounded quantification which could render checking 
undecidable~\cite{piercebook}.

To solve this problem, we introduce \emph{abstract refinements} 
which let us 
quantify or parameterize a type over its constituent refinements.
For example, we can type @max@ as
\begin{code}
  max :: forall <p :: Int -> Bool>. Int<p> -> Int<p> -> Int<p>
\end{code}
where @Int<p>@ is an abbreviation for the refinement type {@{v:Int | p v}@}.
Intuitively, an abstract refinement @p@ is encoded in the refinement logic 
as an \emph{uninterpreted function symbol}, which satisfies the
\emph{congruence} axiom~\cite{Nelson81}
%
$$\forall \overline{X}, \overline{Y}: (\overline{X} = \overline{Y})
\Rightarrow P(\overline{X}) = P(\overline{Y})$$
%
Thus, it is trivial to verify, with an SMT solver, that @max@ 
enjoys the above type: the input types ensure that both @p x@ and @p y@ 
hold and hence the returned value in either branch satisfies 
the refinement  @{v:Int | p v}@, thereby ensuring the output 
type. By the same reasoning, we can generalize the type of @maximum@ 
to
\begin{code}
  maximum :: forall <p :: Int -> Bool>. [Int<p>] -> Int<p>
\end{code}
Consequently, we can recover the verification of @maxEvens@.
Now, instead of instantiating a \emph{type} parameter, we simply instantiate
the \emph{refinement} parameter of @maximum@ with the concrete 
refinement 
@{\v -> v % 2 = 0}@,
after which type checking proceeds as usual \cite{LiquidPLDI08}. 
%
Later, we show how to retain automatic verification by inferring
refinement parameter instantiations via liquid typing
(\S~\ref{sec:abstractrefinements:infer}).

\mypara{Parametric Invariants and Type Classes}
The example above regularly arises in practice, due to type classes. 
In Haskell, the functions above are typed
%
\begin{code}
  (<=)    :: (Ord a) => a -> a -> Bool
  max     :: (Ord a) => a -> a -> a
  maximum :: (Ord a) => [a] -> a
\end{code}
%
We might be tempted to ignore the typeclass constraint 
and treat \ttcode{maximum} as @[a] -> a@. 
This would be quite unsound, as typeclass predicates preclude
universal quantification over refinement types. 
Consider the function @sum :: (Num a) => [a] -> a@ which adds the elements 
of a list.
%Clearly,
The @Num@ class constraint implies that numeric operations occur 
in the function, so
if we pass @sum@ a list of odd numbers, 
we are \emph{not} guaranteed to get back an odd number. 

%Thus, given that we cannot instantiate class-predicated type 
%parameters with arbitrary refinement types, 

Thus, how do we soundly verify the desired type of @maxEvens@ 
without instantiating class predicated type parameters with 
arbitrary refinement types? First, via the same analysis as 
the monomorphic @Int@ case, we establish that
%
\begin{code}
  max    :: forall <p :: a -> Bool>. (Ord a) => a<p> -> a<p> -> a<p>
  maximum:: forall <p :: a -> Bool>. (Ord a) => [a<p>] -> a<p>
\end{code}
%
Next, at the call-site for @maximum@ in @maxEvens@ we
instantiate the type variable @a@ with @Int@ and 
the abstract refinement @p@ with @{\v -> v % 2 = 0}@
after which, the verification proceeds as described
earlier (for the @Int@ case).
Thus, abstract refinements allow us to quantify over 
invariants without relying on parametric polymorphism, 
even in the presence of type classes.

\subsection{Index-Dependent Invariants}\label{sec:overview:index}

Next, we illustrate how abstract invariants allow us to 
specify and verify index-dependent invariants of key-value maps. 
To this end, we develop a small library of \emph{extensible vectors} 
encoded, for purposes of illustration, as functions from @Int@ to 
some generic range @a@. Formally, we specify vectors as 
%
\begin{code}
  data Vec a <dom :: Int -> Bool, rng :: Int -> a -> Bool> 
    = V (i:Int<dom> -> a <rng i>)
\end{code}
%
Here, we are parameterizing the definition of the type @Vec@ 
with \emph{two} abstract refinements, @dom@ and @rng@, which
respectively describe the \emph{domain} and \emph{range} of the vector.
That is, @dom@ describes the set of \emph{valid} indices
and @r@ specifies an invariant relating each @Int@ index
with the value stored at that index.

\mypara{Creating Vectors}
We can use the following basic functions to create vectors:
%
\begin{code}
  empty :: forall <p :: Int -> a -> Bool>.Vec<{\_ -> False}, p> a
  empty = V (\_ -> error "Empty Vec")

  create :: x:a -> Vec <{\_ -> True}, {\_ v -> v = x}> a
  create x = V (\_ -> x)
\end{code}
%
The signature for @empty@ states that its domain is empty (\ie is
the set of indices satisfying the predicate @False@) and that the
range satisfies @any@ invariant. The signature for @create@,
instead, defines a \emph{constant} vector that maps every index to the
constant @x@.

\mypara{Accessing Vectors}
We can write the following @get@ function for reading the contents
of a vector at a given index:
%
\begin{code}
  get :: forall <d :: Int -> Bool, r :: Int -> a -> Bool>
         i:Int<d> -> Vec<d, r> a -> a<r i>
  get i (V f) = f i
\end{code}
%
The signature states that for any domain @d@ and range @r@,
if the index @i@ is a valid index, \ie is of type, \verb+Int<d>+ 
then the returned value is an \verb+a+ that additionally satisfies the
range refinement at the index @i@.
%
The type for @set@, which \emph{updates} the vector at
a given index, is even more interesting, as it allows us to 
\emph{extend} the domain of the vector:
%
\begin{code}
  set :: forall <d :: Int -> Bool, r :: Int -> a -> Bool>
         i:Int<d>
      -> a<r i>
      -> Vec<d && {\k -> k != i}, r> a
      -> Vec<d, r> a
  set i v (V f) = V (\k -> if k == i then v else f k)
\end{code}
%
The signature for @set@ requires that 
(a)~the input vector is defined everywhere at @d@ \emph{except}
the index @i@ and 
(b)~the value supplied must be of type @a<r i>@, \ie satisfy the range 
relation at the index @i@ at which the vector is being updated.
The signature ensures that the output vector is defined at
@d@ and each value satisfies the index-dependent range refinement @r@.
%
Note that it is legal to call @get@ with a vector that is \emph{also} 
defined at the index @i@ since, by contravariance, such a vector is a
subtype of that required by (a).


\mypara{Initializing Vectors} Next, we can write the following function,
@init@, that ``loops" over a vector, to @set@ each index to 
a value given by some function.
%
\begin{code}
  initialize :: forall <r :: Int -> a -> Bool>.
                (z: Int -> a<r z>) 
             -> i: {v: Int | v >= 0} 
             -> n: Int 
             -> Vec <{\v -> 0 <= v && v < i}, r> a 
             -> Vec <{\v -> 0 <= v && v < n}, r> a 

  initialize f i n a 
    | i >= n    = a
    | otherwise = initialize f (i+1) n (set i (f i) a)
\end{code}
%
The signature requires that 
(a)~the higher-order function @f@ produces values that satisfy 
the range refinement @r@ and 
(b)~the vector is initialized from @0@ to @i@.
%
The function ensures that the output vector is initialized from @0@
through @n@.
%
We can thus verify that
%
\begin{code}
  idVec   :: Vec <{\v -> 0<=v && v<n}, {\i v -> v=i}> Int
  idVec n = initialize (\i -> i) 0 n empty
\end{code}
%
\ie @idVec@ returns a vector of size @n@ where each
key is mapped to itself. Thus, abstract refinement types allow us 
to verify low-level idioms such as the incremental initialization 
of vectors, which have previously required 
special analyses~\cite{Gopan05,JhalaMcMillanCAV07,CousotsPOPL11}.

\mypara{Null-Terminated Strings}
%
We can also use abstract refinements to verify code which 
manipulates C-style null-terminated strings, 
represented as @Char@ vectors for ease of exposition.
Formally, a null-terminated string of size @n@ has the type
%
\begin{code}
  type NullTerm n 
    = Vec <{\v -> 0<=v<n}, {\i v -> i=n-1 => v='\0'}> Char
\end{code}
%%Vec <{\v -> 0 <= v && v < n},
%%     {\i v -> i = n - 1 => v = '\0'}>
%%    Char
%
The above type describes a length-@n@ vector of characters whose
last element must be a null character, signalling the end of
the string.
%
We can use this type in the specification of a function,
@upperCase@, which iterates through the characters of a string,
uppercasing each one until it encounters the null terminator:
%
%  Vec <{\v -> 0 <= v && v < n},
%       {\i v -> i = n - 1 => v = '\0'}>
%      Char ->
%  Vec <{\v -> 0 <= v && v < n},
%       {\i v -> i = n - 1 => v = '\0'}>
%      Char
% upperCase n s = ucs 0 s where
%   ucs i s = let c = get i s in
%             if c == '\0' 
%               then s
%               else ucs (i + 1) (set i (toUpper c) s)
\begin{code}
  upperCase :: n:{v: Int| v>0} -> NullTerm n -> NullTerm n
  upperCase n s = ucs 0 s 
    where
      ucs i s = case get i s of
                  '\0' -> s
                  c    -> ucs (i + 1) (set i (toUpper c) s)
\end{code}
%
Note that the length parameter @n@ is provided solely as a ``witness''
for the length of the string @s@, which allows us to use the length of
@s@ in the type of @upperCase@; @n@ is not used in the
computation.
%
In order to establish that each call to @get@ accesses string @s@
within its bounds, our type system must establish that, at each call
to the inner function @ucs@, @i@ satisfies the type
@{v: Int | 0 <= v && v < n}@.
%
This invariant is established as follows.
%
First, the invariant trivially holds on the first call to @ucs@, as
@n@ is positive and @i@ is $0$.
%
Second, we assume that @i@ satisfies the type
%
@{v: Int | 0 <= v && v < n}@,
%
and, further, we know from the types of @s@ and @get@ that @c@ has the
type @{v: Char | i = n - 1 => v = '\0'}@.
%
Thus, if @c@ is non-null, then @i@ cannot be equal to @n - 1@.
%
This allows us to strengthen our type for @i@ in the else branch to
@{v: Int | 0 <= v && v < n - 1}@ and thus to conclude that the value
@i + 1@ recursively passed as the @i@ parameter to @ucs@ satisfies the
type @{v: Int | 0 <= v && v < n}@, establishing the inductive
invariant and thus the safety of the @upperCase@ function.

\mypara{Memoization} 
Next, let us illustrate how the same expressive signatures allow us to
verify memoizing functions. We can specify to the SMT solver the 
definition of the Fibonacci function via an uninterpreted function 
@fib@ and an axiom:
%
\begin{code}
  measure fib :: Int -> Int
  axiom: forall i. (fib i) = if i <= 1 then 1 else fib (i-1) + fib (i-2)
\end{code}
%axiom_fib :: i:Int -> {v: Bool | (? v) <=> (fib(i) = i <= 1 ? 1 : fib(i-1) + fib(i-2))}
%
Next, we define a type alias @FibV@ for the vector 
whose values are either @0@ (\ie undefined) or 
equal to the Fibonacci number of the corresponding index. 
%(We use @Int@ instead of @Maybe Int@ as the domain for brevity.)
%
\begin{code}
  type FibV = Vec<{\_->True},{\i v-> v != 0 => v = fib i}> Int 
\end{code}
%
Finally, we can use the above alias to verify @fastFib@, 
an implementation of the Fibonacci function, which uses 
a vector memoize intermediate results 
%
\begin{code}
  fastFib   :: n:Int -> {v:Int | v = fib(n)}
  fastFib n = snd $ fibMemo (create 0) n

  fibMemo :: FibV -> i:Int -> (FibV, {v: Int | v = fib(i)})   
  fibMemo t i 
    | i <= 1    = (t, 1)
    | otherwise = case get i t of   
                    0 -> let (t1, n1) = fibMemo t  (i-1)
                             (t2, n2) = fibMemo t1 (i-2)
                             n        = n1 + n2 
                         in  (set i n t2,  n)
                    n -> (t, n)
\end{code} %$ 
%
%% axiom_fib :: i:Int -> {v: Bool | (? v) <=> (fib(i) = i <= 1 ? 1 : fib(i-1) + fib(i-2))}
%%
%% fibMemo t i 
%%   | i <= 1    
%%   = (t, assume (axiom_fib i) $ 1)
%%   
%%   | otherwise 
%%   = case get i t of   
%%       0 -> let (t1, n1) = fibMemo t  (i-1)
%%                (t2, n2) = fibMemo t1 (i-2)
%%                n        = assume (axiom_fib i) $ n1 + n2
%%            in  (set i n t2,  n)
%%       n -> (t, n)
%
Thus, abstract refinements allow us to define key-value maps with
index-dependent refinements for the domain and range. 
Quantification over the domain and range refinements allows us
to define generic access operations (\eg @get@, @set@,
@create@, @empty@) whose types enable us establish
a variety of precise invariants.

\subsection{Recursive Invariants}\label{sec:overview:rec}

Next, we turn our attention to recursively defined datatypes and show 
how abstract refinements allow us to specify and verify high-level
invariants that relate the elements of a recursive structure.
Consider the following refined definition for lists:
%
\begin{code}
  data [a] <p :: a -> a -> Bool> where
    []  :: [a]<p>
    (:) :: h:a -> [a<p h>]<p> -> [a]<p>
\end{code}
%data List <p :: a -> a -> Bool> a where
%  Nil  :: List<p> a 
%  Cons :: h:a -> List<p> (a<p h>) -> List<p> a
%
%% data List a <p :: a -> a -> Bool>  
%%   = Cons { head :: a
%%          , tail :: List <p> (a <p head>) }
%%   | Nil
%% \end{code}
%
The definition states that a value of type @[a]<p>@ 
is either empty (@[]@) or constructed from a pair of  
a \emph{head} @h::a@ and a \emph{tail} of a list of 
@a@ values \emph{each} of which satisfies the refinement @(p h)@. 
Furthermore, the abstract refinement @p@ holds recursively
within the tail, ensuring that the relationship @p@ 
holds between \emph{all} pairs of list elements.

Thus, by plugging in appropriate concrete refinements, 
we can define the following aliases, which correspond 
to the informal notions implied by their names:
\begin{code}
  type IncrList a = [a]<{\h v -> h <= v}>
  type DecrList a = [a]<{\h v -> h >= v}>
  type UniqList a = [a]<{\h v -> h != v}>
\end{code}
%%
%\begin{code}
%type IncList a    = List <{\h v -> h <= v}> a 
%type DecList a    = List <{\h v -> h >= v}> a 
%type UniqueList a = List <{\h v -> h != v}> a 
%\end{code}
%
That is, @IncrList a@ (resp. @DecrList a@) describes a list sorted
in increasing (resp. decreasing) order and @UniqList a@ describes
a list of \emph{distinct} elements, \ie not containing any duplicates.
We can use the above definitions to verify
%
\begin{code}
  [1, 2, 3, 4] :: IncrList Int
  [4, 3, 2, 1] :: DecrList Int
  [4, 1, 3, 2] :: UniqList Int
\end{code}
%
%
%\begin{code}
%xs :: IncList Int
%xs = 1 `Cons` 2 `Cons` 3 `Cons` 4 `Cons` Nil
%
%ys :: IncList Int
%ys = 4 `Cons` 3 `Cons` 2 `Cons` 1 `Cons` Nil
%
%zs :: UniqueList Int
%zs = 4 `Cons` 1 `Cons` 3 `Cons` 2 `Cons` Nil
%\end{code}
%
More interestingly, we can verify that the usual algorithms 
produce sorted lists:
%
\begin{code}
  insertSort :: (Ord a) => [a] -> IncrList a 
  insertSort []     = []
  insertSort (x:xs) = insert x (insertSort xs) 
  
  insert :: (Ord a) => a -> IncrList a -> IncrList a 
  insert y []       = [y]
  insert y (x:xs) 
    | y <= x        = y : x : xs
    | otherwise     = x : insert y xs
\end{code}
%
%insertSort        :: (Ord a) => List a -> IncList a 
%insertSort Nil           = Nil 
%insertSort (x `Cons` xs) = insert x (insertSort xs) 
%
%insert y Nil                  
%  = y `Cons` Nil 
%insert y (Cons x xs) 
%  | y <= x    = y `Cons` (x `Cons` xs) 
%  | otherwise = x `Cons` (insert y xs)
%
%
Thus, abstract refinements allow us to \emph{decouple} the definition 
of the list from the actual invariants that hold.
This, in turn, allows us to conveniently reuse the same 
underlying (non-refined) type to implement various algorithms 
unlike, say, singleton-type based implementations which require 
up to three different types of lists (with three different ``nil" and ``cons" 
constructors~\cite{Sheard06}). This, makes abstract refinements 
convenient for verifying complex sorting implementations like that of 
@Data.List.sort@ which, for efficiency, use lists with different 
properties (\eg increasing and decreasing).

\mypara{Multiple Recursive Refinements} 
We can define recursive types with multiple parameters. 
For example, consider the following refined version of a type used 
to encode functional maps (\ttcode{Data.Map}):
%
\begin{code}
  data Tree k v <l :: k -> k -> Bool, r :: k -> k -> Bool>
    = Bin { key   :: k
          , value :: v 
          , left  :: Tree <l, r> (k <l key>) v 
          , right :: Tree <l, r> (k <r key>) v }
    | Tip
\end{code}
%
The abstract refinements \ttcode{l} and \ttcode{r} relate each \ttcode{key}
of the tree with \emph{all} the keys in the \emph{left} and \emph{right}
subtrees of \ttcode{key}, as those keys are respectively of type 
\ttcode{k <l key>} and \ttcode{k <r key>}.
%
Thus, if we instantiate the refinements with the following predicates
\begin{code}
  type BST k v     = Tree<{\x y -> x> y},{\x y-> x< y}> k v
  type MinHeap k v = Tree<{\x y -> x<=y},{\x y-> x<=y}> k v
  type MaxHeap k v = Tree<{\x y -> x>=y},{\x y-> x>=y}> k v
\end{code}
then @BST k v@, @MinHeap k v@ and @MaxHeap k v@ 
denote exactly binary-search-ordered, min-heap-ordered, and
max-heap-ordered trees (with keys and values of types @k@ and
@v@).  
%
We demonstrate in (\S~\ref{sec:experiments}) how we use the above types to 
automatically verify ordering properties of complex, full-fledged libraries.

\subsection{Inductive Invariants}\label{sec:overview:induction}

Finally, we explain how abstract refinements allow us to formalize 
some kinds of structural induction within the type system. 

\mypara{Measures} First, let us formalize a notion of \emph{length} for
lists within the refinement logic. To do so, we define a special 
\ttcode{len} measure by structural induction
%
\begin{code}
  measure len :: [a] -> Int 
    len []      = 0 
    len (x:xs)  = 1 + len(xs)
\end{code}
%
We use the measures to automatically strengthen the 
types of the data constructors~\ref{sec:measures}:
%
\begin{code}
  data [a] where 
    []  :: {v:[a] | len v = 0}
    (:) :: a -> xs:[a] -> {v:[a]| len v = 1 + len xs}
\end{code}
%
Note that the symbol \ttcode{len} is encoded as an \emph{uninterpreted}
function in the refinement logic, and is, except for the congruence axiom,
opaque to the SMT solver. The measures are guaranteed, by construction, 
to terminate and so we can soundly use them as uninterpreted 
functions in the refinement logic. Notice also, that we can define 
\emph{multiple} measures for a type; in this case we simply conjoin 
the refinements from each measure when refining each data constructor.

With these strengthened constructor types, we can verify, for example,
that @append@ produces a list whose length is the sum of the input lists'
lengths:
%
\begin{code}
  append :: l:[a] -> m:[a] -> {v:[a]| len v = len l + len m}
  append []     zs = zs
  append (y:ys) zs = y : append ys zs
\end{code}
%
However, consider an alternate definition of @append@ that uses @foldr@
%
\begin{code}
  append ys zs = foldr (:) zs ys 
\end{code}
%
where @foldr :: (a -> b -> b) -> b -> [a] -> b@.
It is unclear how to give @foldr@ a (first-order) refinement type
that captures the rather complex fact that the fold-function 
is ``applied" all over the list argument, or, that it is a catamorphism.
Hence, hitherto, it has not been possible to verify the second definition 
of @append@.


\mypara{Typing Folds} Abstract refinements allow us to 
solve this problem with a very expressive type for \ttcode{foldr} 
whilst remaining firmly within the boundaries of SMT-based 
decidability. We write a slightly modified fold:
%
\begin{code}
  foldr :: forall <p :: [a] -> b -> Bool>. 
           (xs:[a] -> x:a -> b <p xs> -> <p (x:xs)>) 
        -> b<p []> 
        -> ys:[a]
        -> b<p ys>
  foldr op b []     = b
  foldr op b (x:xs) = op xs x (foldr op b xs) 
\end{code}
%
The trick is simply to quantify over the relationship @p@
that @foldr@ establishes between the input list @xs@ and
the output @b@ value. This is formalized by the type signature,
which encodes an induction principle for lists: 
the base value @b@ must 
(1)~satisfy the relation with the empty list,
and the function @op@ must take 
(2)~a value that satisfies the relationship with the tail 
    @xs@ (we have added the @xs@ as an extra ``ghost"
    parameter to @op@), 
(3)~a head value @x@, and return
(4)~a new folded value that satisfies the relationship with \ttcode{x:xs}.
If all the above are met, then the value returned by @foldr@
satisfies the relation with the input list @ys@.
%
This scheme is not novel in itself~\cite{coq-book}
--- what is new is the encoding, via uninterpreted predicate symbols, 
in an SMT-decidable refinement type system.

\mypara{Using Folds} Finally, we can use the expressive type
for the above @foldr@ to verify various inductive properties 
of client functions:
%
\begin{code}
  length :: zs:[a] -> {v: Int | v = len zs}
  length = foldr (\_ _ n -> n + 1) 0

  append :: l:[a] -> m:[a] -> {v:[a]| len v = len l + len m}
  append ys zs = foldr (\_ -> (:)) zs ys 
\end{code}
%
The verification proceeds by just (automatically) instantiating the 
refinement parameter \ttcode{p} of \ttcode{foldr} with the concrete
refinements, via Liquid typing:
%
\begin{code}
  {\xs v -> v = len xs}                 -- for length
  {\xs v -> len v = len xs + len zs}    -- for append
\end{code}

%%This concludes a tour of the many kinds of expressive specifications
%%that abstract refinements enable, while preserving fully automatic
%%verification. 
