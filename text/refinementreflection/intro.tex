In this chapter we introduce \emph{Refinement Reflection}, a method
to extend \emph{legacy} languages---with highly tuned
libraries, compilers, and run-times---into theorem provers,
by letting programmers specify and verify
arbitrary properties of their code simply
by writing programs in the legacy language.

Refinement types, as presented so far, offer a
form of programming with proofs that can be
retrofitted into a programming language.
%
The retrofitting relies upon restricting refinements
to so-called ``shallow'' specifications that
correspond to \emph{abstract} interpretations
of the behavior of functions.
%
For example, refinements make it easy to specify
that the list returned by the @append@ function
has size equal to the sum of those of its inputs.
%
These shallow specifications fall within decidable
logical fragments, and hence, can be automatically
verified using SMT based refinement typing.

Refinements are a pale shadow of what is possible
with dependently typed languages like Coq, Agda
and Idris which permit ``deep'' specification
and verification.
%
These languages come equipped with mechanisms
that \emph{represent} and \emph{manipulate} the
exact descriptions of user-defined functions.
%
For example, we can represent the specification
that the @append@ function is associative, and we
can manipulate (unfold) its definition to write a
small program that constructs a proof of the
specification.
%
Dafny~\citep{dafny}, \fstar~\citep{fstar} and
Halo~\citep{halo} take a step towards
SMT-based deep verification, by encoding
user-defined functions as universally
quantified logical formulas or ``axioms''.
%
This axiomatic approach offers significant automation
but relies heavily upon
brittle heuristics for ``triggering'' axiom instantiation,
giving away decidable, and hence, predictable
verification~\citep{Leino16}.
%

In this chapter, we present a new approach to retrofitting
deep verification into existing languages. Our approach
reconciles the automation of SMT-based refinement typing
with decidable and predictable verification, and enables
users to reify pencil-and-paper proofs simply
as programs in the source language.
\begin{itemize}
\item % {Refinement Reflection}
%
We start this chapter by an overview of 
refinement reflection: the code
implementing a​ user-defined function can
be \emph{reflected}​ into the function's
(output) refinement type, thus converting
the function's (refinement) type signature
into a deep specification of the functions
behavior.
%
This simple idea has a profound consequence:
at \emph{uses} of the function, the standard
rule for (dependent) function application
yields a precise, predictable and most
importantly, programmer controllable
means of \emph{instantiating} the deep
specification that is not tethered to
brittle SMT heuristics.
%
Specifically, we show how to use ideas for
\emph{defunctionalization} from the theorem
proving literature which encode functions
and lambdas using uninterpreted symbols,
to encode terms from an expressive higher
order language as decidable refinements,
letting us use SMT-based congruence
closure for decidable and predictable
verification~(\S~\ref{sec:refinementreflection:theory}).

\item % {A Library of Proof Combinators}
%
Next, we present a
\emph{library of combinators}
that lets programmers
\emph{compose proofs}
from basic refinements
and function definitions.
%
We show how to represent proofs
simply as unit-values refined
by the proposition that
they prove. %~(\S~\ref{sec:library}).
%
We show how to build up sophisticated proofs
using a small library of combinators that
permits reasoning in an algebraic or
equational style.
%
Furthermore, since proofs are literally
just programs, our proof combinators let
us use standard language mechanisms like
branches (to encode case splits),
recursion (to encode induction), and
functions (to encode auxiliary lemmas)
to write proofs that look very much like
transcriptions of their pencil-and-paper
analogues~(\S~\ref{sec:overview}).

\item % {Verified Typeclass Laws}
%
We implemented refinement reflection in \toolname~\citep{Vazou14},
thereby converting the legacy language
Haskell into a theorem prover.
%
We demonstrate the benefits of this conversion
by proving typeclass laws.
%
Haskell's typeclass machinery has led to
a suite of expressive abstractions and optimizations
which, for correctness, crucially require
typeclass \emph{instances} to obey key algebraic laws.
We show how reflection can be used to formally verify
that many widely used instances of the Monoid, Applicative,
Functor, and Monad typeclasses actually satisfy the
respective laws, making the use of these typeclasses safe~(\S~\ref{sec:evaluation}).

\item % {Verified Deterministic Parallelism}
Finally, to showcase the benefits of retrofitting
theorem proving onto legacy languages, we perform
a case study in \emph{deterministic parallelism}.
%
%
Existing deterministic languages place unchecked
obligations on the user to guarantee, \eg the
associativity of a fold.
%
Violations can compromise type soundness
and correctness.
%
Closing this gap requires only modest proof
effort---touching only a small subset of
the application.
%
But for this solution to be possible requires a
\emph{practical}, \emph{parallel} programming
language that supports deep verification.
%
Before \toolname there was no such parallel language.
%
% Refinement reflection opens up this new possibility
% paving the way towards high-performance with
% correctness guarantees.
%
We show how \toolname lets us verify the unchecked obligations
from benchmarks taken from three existing parallel programming 
systems, and thus, paves the way towards 
high-performance with correctness guarantees~(\S~\ref{sec:eval-parallelism}).
\end{itemize}
